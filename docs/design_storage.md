# Design Doc: Storage

## Basics
存储引擎设计为内存中的列存储, 被组织成1 MB的块
它与并发控制系统和垃圾回收机制完全集成. 我们使用 HyPer-style 的MV-OCC, 带有增量存储、最新到最旧和就地更新. 目前仅实现了快照隔离, 因此尚不需要验证阶段. 参考
[this paper](https://15721.courses.cs.cmu.edu/spring2018/papers/06-mvcc2/p677-neumann.pdf).

## Block Organization
如前所述, 我们将数据组织成1 MB的块. 这些块内部组织类似于
[PAX](http://www.pdl.cmu.edu/PDL-FTP/Database/pax.pdf), 但需要进行修改以适应内存设置. 显著变化包括:

- 缺乏“id”概念. 由于它们在内存中, 物理指针足以标识它们
- 缺乏变长字段概念. 我们存储物理指针到专用变长池(dedicated varlen pools)中的条目
- 增加了“布局版本”(layout version)字段, 用于支持并发模式

实际布局如下:

```
-----------------------------------------------------------------------
| layout_version (32-bit) | num_records (32-bit) | num_slots (32-bit) |
-----------------------------------------------------------------------
| attr_offsets[num_attrs] (32-bit) |       num_attrs (16-bit)         |
-----------------------------------------------------------------------
| attr_sizes[num_attrs] (8-bit) |  Miniblock 1 | Miniblock 2 |   ...  |
-----------------------------------------------------------------------
```

这里的`Miniblock`就是我们存储整个列的方式. 它的内部布局如下:

```
-------------------------------------------------------------------------------
| null_bitmap[num_slots] (1-bit) | attr_values[num_slots] (size of attribute) |
-------------------------------------------------------------------------------
```

注意, 所有内容都填充到与其自身大小对齐, 每个`Miniblock`都以8字节对齐

Be aware that we use least-significant byte order (LSB) within each byte if the bitmap.(?)

## Storage Layer Overview

存储引擎设计为仅具有physical-level存储概念(字节、指针等), 通常没有SQL-level构造(如类型、约束、变长条目等)的概念, 可以被视为仅存储固定长度对象的键值(key-value)存储. 这意味着存储引擎将依赖外部索引和执行引擎检查来强制执行SQL-level规则, 并存储变长条目的物理指针

## A Standardized Storage Layer Vocabulary

以下是我们系统中一些模糊术语的使用方式:

- offset: number of bytes to jump from a known location to get to something. (`attr_offsets`)
- index: usually index of a list, for example indexes within the projection list in a `ProjectedRow`.
- column id: within a block, the index assigned to the column in the array fields (`attr_offsets`, `attr_sizes`, etc.) This is
             given special meaning in the system as it is the canonical representation of a column in a table.
- attribute: A single value within a tuple

## Storage API

以下是存储层中各种类和概念的高级描述. Code-level APIs are documented via doxygen.

### TupleSlot
------
我们使用`TupleSlot`作为存储对象的键, 它总是直接对应于物理内存位置. 更具体地说, `TupleSlot`类似于Postgres的`ctid`, 它是一个块ID和块偏移量的对. 由于我们在内存中, 我们只需使用块起始的原始指针, 而不是块ID, 并使用一些位打包技巧(bit-packing tricks)将两个值放入一个64位值中.

由于所有块都是1 MB大小, 因此可以保证两个块的头始终至少相隔1 MB, 并且我们可以根据已知的块起始位置确定任何给定物理指针可能在哪个块中. 我们利用这一事实, 始终将块的头对齐到1 MB. 然后, 我们只需要64位指针中的64 - 20 = 44位来定位块的头. 剩余的20位保证足够大以容纳块内的可能偏移值, 因为任何元组至少必须有1字节大小, 因此一个块中最多可以有2 ^ 20个元组和唯一偏移量.

实际上, 由于头和其他元数据, 我们甚至还有几个额外的位可以节省. 如果将来需要在`TupleSlot`中打包更多状态, 这可能很有用.

### BlockLayout and TupleAccessStrategy
------
由于需要一些计算来正确布局带有填充的块, 并计算块在这些填充下将有多少个槽, 大部分工作都是预先完成的(done up-front), 并存储在`TupleAccessStrategy`对象中. 我们最初打算让对象作为编译代码的替代品(stand-in), 但事实证明, 只需预先(up-front)进行这些计算, 我们已经非常快速. 您需要一个`TupleAccessStrategy`才能正确初始化和解释块.

`BlockLayout`是一个描述块中存储的列及其大小的只读元数据. 它本质上是我们用来传递有关块信息的值对象.

### VarlenEntry
------
变长值在我们的系统中存储为16字节的列, 可能包含指向堆上实际变长值的内存块的指针. 这是16字节, 因为我们可能需要存储一个8字节指针和一个4字节大小字段, 并确保所有值在存储在列中时对齐. 对于较小的变长值, 这很浪费, 因此我们可以选择内联值而不是存储指针. `VarlenEntry`对象中成员的布局图如下:

```
---------------------------------------------------------------
| size (4-byte) | prefix (4-byte) | pointer / suffix (8-byte) |
---------------------------------------------------------------
```

4字节大小和8字节指针之间的填充用于存储变长值的前4个字节, 以促进潜在的快速过滤. 请注意, 前缀是副本(a copy), 指向的变长条目仍然包含这些字节. 在大小小于或等于12的情况下, 我们能够将整个变长值存储在此对象中并省略指针. 值从前缀成员的开始连续存储, 指针字段用作后缀. 请注意, 在此设置中, 访问内联值的前缀仍返回正确的前缀, 对`Content()`的调用保留非内联版本的语义(如果内联, 则返回`Prefix()`). 始终使用提供的函数`InlineThreshold()`和`PrefixSize()`访问前缀和内联阈值, 以避免magic numbers.

要创建`VarlenEntry`, 请使用静态工厂方法`VarlenEntry::Create`和`VarlenEntry::CreateInline`. 调用者负责通过将变长的大小与`InlineThreshold()`进行比较来检查应使用哪一个. 我们不在构造函数中包含此检查的原因是, 根据条目是否内联, 对象要么接管所有权(如果不是内联), 要么不接管所有权(如果是内联), 并且拆分构造函数迫使程序员考虑这一点.

大小字段的符号位用于跟踪GC是否允许释放变长条目的指针值. 变长条目可能指向Arrow变长缓冲区或压缩块的字典, 这些不能自行释放. 只需调用`NeedReclaim`即可查看是否需要由GC作为独立条目回收.

### DataTable
------
目前, `DataTable`是一个简单的 "key"-value 存储, 也是事务性的并支持多版本. key用`"`引起来, 因为我们使用`TupleSlot`作为查找元组的key, 这不是客户端提供的, 实际上表示内存中的物理位置.

### ProjectedRow and ProjectedColumns
------
作为增量存储系统(delta-storage system), 元组的局部图像(partial image)概念是存储引擎的核心. 通常, 我们使用`ProjectedRow`来表示部分元组. `ProjectedRow`并不是一个真正的对象, 而是被重新解释为具有以下布局的内存块:

```
 -------------------------------------------------------------------------------
 | size | num_cols | col_id1 | col_id2 | ... | val1_offset | val2_offset | ... |
 -------------------------------------------------------------------------------
 | null-bitmap (pad up to byte) | val1 | val2 | ...                            |
 -------------------------------------------------------------------------------
```

我们使用这种结构作为存储引擎的输入和输出, 并嵌入到(embedded into)并发控制系统(the concurrency control system)的重做(redo)和撤销(undo)记录中.

与`ProjectedRow`类似的是`ProjectedColumns`的概念, 只是这些对象同时持有多个元组, 并且每个列连续布局. 更具体地说, `ProjectedColumns`的内存布局如下:

```
 -----------------------------------------------------------------------
 | size | max_tuples | num_tuples | num_cols | col_id1 | col_id2 | ... |
 -----------------------------------------------------------------------
 | val1_offset | val2_offset | ... | TupleSlot_1 | TupleSlot_2 |  ...  |
 -----------------------------------------------------------------------
 | null-bitmap, col_id1 | val1, col_id1 | val2, col_id1 |      ...     |
 -----------------------------------------------------------------------
 | null-bitmap, col_id1 | val1, col_id2 | val2, col_id2 |      ...     |
 -----------------------------------------------------------------------
 |                                ...                                  |
 -----------------------------------------------------------------------
```

我们在提供存储数据的向量化访问时使用这种结构, 例如在顺序扫描时. 我们需要这样做的原因是, 作为增量存储(delta-store), 我们总是需要在处理之前具体化一个元组. 这也意味着一个填充的`ProjectedColumns`对象保证没有任何空洞, 即元组总是从位置0填充到`num_tuples`, 它们的源`TupleSlot`在相应的`TupleSlot`列表位置.


## Concurrency Control

我们使用 HyPer-style 的多版本并发控制来管理系统的并发. 并发控制系统基于增量(delta based), 并就地(in-place)更新记录. 我们强烈建议您完整阅读原始论文以了解上下文, 但我们将在这里总结重要部分. 然后, 我们将描述我们自己的实现.

### Isolation Level
------
当前存储引擎仅支持快照隔离, 这不能防止写偏斜(write skews)或幻影(phantoms). HyPer论文详细说明了如何在当前系统之上实现MV-OCC的变体以实现完全序列化(achieve full serializability). 由于这一点, HyPer模型的一些细节被更改或未实现.

### Timestamps
------
我们使用简单的逻辑时间戳来排序事务. HyPer论文指出, 事务在其生命周期中将获得三个时间戳: 开始时间戳(begin timestamp)、提交时间戳(commit timestamp)(如果事务提交), 和一个逻辑上大于任何可能的开始或提交时间戳的唯一标识事务ID(uniquely-identifying transaction id)(64位整数中的负值, 但作为无符号处理).

在我们的实现中, 事务仅接收两个时间戳, 并且我们从事务的开始时间戳派生(derive)“事务ID”(transaction id), 因为它们已经是唯一标识的(uniquely-identifying). 我们只需翻转开始时间戳的符号位(flip the sign bit of the begin timestamp)即可获得 HyPer-style 的事务ID. 中止的事务不会收到提交时间戳(commit timestamp).

### Lock-free Version Chains
------
我们的并发控制系统通常是无锁的, 除了事务的开始和结束, 在这些情况下, 事务管理器必须原子地更新全局数据结构. 对于每个元组, 我们保留一个特殊的列, 称为“版本向量”(version vector), 它存储一个物理指针, 这将形成一个撤销记录的单链表. 以无锁方式维护所谓的链表, 称为版本链, 是很容易的. 如果没有任何较旧版本可见, 则该列仅为空. 每个版本链节点, 或撤销记录, 存储被修改元组的物理“before-image”, 以及修改它的交易的时间戳. 时间戳要么是事务的ID, 要么是已提交事务的提交时间戳.

在读取元组时, 读取线程首先将最新版本具体化(materializes)到输出缓冲区中, 然后跟随版本链(follows the version chain), 将相关的before-image复制到缓冲区中, 直到从版本链构建出一个可见的版本, 并返回缓冲区. 未提交的版本(uncommited versions)不会被读取, 因为版本上的时间戳将大于任何运行事务的开始时间戳. 有特殊情况逻辑, 以便未提交的事务可以读取其自己的更改.

在更新元组时, 更新线程首先将元组的当前版本复制到撤销(undo)记录中, 然后尝试原子地将记录前置(prepend)到版本链中. 请注意, HyPer, 以及我们, 不允许写-写冲突(write-write conflict), 因此版本链前置充当隐式的“写锁”(write lock), 如果版本链的头对它不可见, 事务将中止. 此时, 事务可以自由地进行就地更改(in-place changes), 因为读取事务无论如何都可以从版本链重建版本(reconstruct the version from the version chain), 并且没有其他事务可以更新该元组.

### Undo Records
------
HyPer采取的一种创新方法(innovative)是将在事务上下文中存储撤销(undo)记录. 它们仍然可以作为链表节点访问, 但事务可以在提交或中止时轻松地在本地遍历所有这些记录. 这取代了传统OCC系统中发现的写集合. (为了对称性(symmetry), 读集合被替换为针对所有最近提交事务的增量进行评估的谓词(predicate), 但这仅与序列化相关)

我们的系统通过嵌入指向我们称为“BufferSegments”的固定大小内存块(fixed-size chunk of memory)的指针向量来实现这一点, 这些内存块是从对象池(object pools)中获取的. 首先, 使用可调整大小的缓冲区的朴素实现(naive implementation)不起作用, 因为调整大小通常会改变元素的内存位置, 这将破坏版本链, 因为原始位置被指向. 我们通过利用系统在事务完成之前永远不会删除记录的事实, 为撤销(undo)记录提供了一个连续、无界的缓冲区(continuous, unbounded buffer)的假象(illusion), 并且事务只按顺序遍历它们. 然后, 我们按顺序填充每个段, 并在下一个条目没有空间时逻辑上请求一个新的段附加到上一个段的末尾.

### Committing and Aborting
------
事务管理器管理事务的生命周期, 并且必须维护几个全局数据结构, 以确保系统的其余部分正确工作:

- 一个全局运行事务表. 我们需要这些信息, 以便垃圾收集器来回收不再可见的事务
- 可能是一个最近提交事务表, 以便事务管理器可以在序列化隔离级别检查正在提交的事务是否存在冲突

在提交时, 事务从事务管理器获取提交时间戳, 并从运行事务表中移除. 然后, 事务遍历其本地撤销缓冲区, 并更改撤销记录中的时间戳, 从而使其更改对系统的其余部分可见.

我们目前没有实现第二个数据结构, 这导致了罕见的竞态条件(rare race conditions). 首先注意到, 我们描述的提交过程不是原子的, 并且不能是原子的, 因为事务可以有任意大的写集合. 如果一个事务在另一个事务正在更改其撤销记录上的时间戳时开始, 它可能会在较早的读取中跳过正在提交的版本, 并在从正在提交的事务的较晚读取中看到正在提交的版本, 因为在第一个读取中翻转尚未发生, 但在第二个读取中已经完成. 或者, 事务最初可以读取先前版本, 在提交事务翻转之前, 并在提交完成后返回到同一个元组, 导致不可重复读. 这种异常本应在序列化检查中发现, 但由于我们没有实现它, 我们依赖全局共享锁来防止这种情况发生. 具体来说, 在另一个事务正在提交时, 不允许开始新的事务. (HyPer实现也有一个全局锁存器(global latch), 只是他们没有将翻转时间戳(flipping timestamps)包含在临界区(critical section)中. )

在中止时, 同样地, 事务管理器从运行事务表中移除事务. 此外, 事务的所有更改都需要被还原(reverted). 这可以通过遍历事务的撤销缓冲区, 将before-image复制到最新版本(撤销更改, undoing the change), 并原子地从版本链中解除记录的链接来轻松完成.

## Garbage Collection

新系统的一个重要observation是, 所有需要清理的数据都位于事务上下文本身中. 这优雅地消除(eliminates)了对全表真空(?, full table vacuums)或协作垃圾收集(collaborative garbage collection)的需求, 因为GC所需的信息不再与表本身相关联.

事务管理器本质上保持一个已完成事务的后队列(back queue). 然后, 垃圾收集器是一个简单的后台线程, 周期性地从事务管理器的队列(transaction manager's queue)中轮询并处理已完成的事务.

完全释放事务上下文需要两个阶段. 在第一阶段, 垃圾收集器将查看系统中仍在运行的最旧事务(oldest transaction), 识别其撤销记录对运行事务不再可见的已提交事务(即, 系统中没有事务在事务提交之前开始), 并从版本链中解除这些记录的链接. 然而, 运行事务仍然可以遍历版本链并落在节点上, 因此我们不能安全地释放或重用这块内存. 我们称这为解除链接阶段(the unlink phase).

为了解决这个问题, 我们记下解除链接记录的时间, 暂时保留这些记录. 当GC线程再次唤醒时, 它首先检查当前运行的事务, 并在最旧的运行事务比解除链接时间更近时(因此它们不能在任何已解除链接的版本上工作)释放这些事务. 我们称这为释放阶段(the deallocation phase).

两个需要注意的警告:

- 中止的事务基本上在中止发生时立即进入解除链接阶段(unlink phase), 并在垃圾收集器中直接进入释放阶段(deallocation phase).
- 释放不是非常激进的. 在整个代码中, 我们做出了决定, 在释放记录可能导致需要复杂解决的竞态条件时, 选择退后并在稍后返回, 以确保正确性. 在没有长时间运行事务的情况下, 这保持得足够好；然而, 在HTAP环境中, 长时间运行的事务可能对我们的垃圾收集器有害. 幸运的是, 对此问题有已知的优化方法. 详见[this paper](https://dl.acm.org/purchase.cfm?id=2903734)

## Write-Ahead Logging and Recovery

新系统中的预写日志(Write-Ahead Logging, WAL)操作与垃圾收集过程非常相似. (事实上, 两者之间存在明显的对称性)当执行更新时, 增量记录实际上被分为两个image: before-image和after-image. 类似于我们在事务上下文中存储撤销(undo)记录(before-image)的方式, 我们可以对重做(redo)记录(after-image)进行同样的操作.

因为我们打算让数据库完全在内存中运行, 所以没有必要跟踪“脏页”(dirty pages), 就像在基于磁盘的系统中那样. 所有持久化的更改都将通过检查点进行, 并且在多版本系统中确保检查点的一致性并不困难. (这本质上是一个事务性的全表扫描. )这意味着在从崩溃中恢复时, 没有任何东西需要撤销, 只需加载检查点并在检查点之后重放日志中所有已提交的操作就足够了.

因此, 我们在预写日志(the write-ahead log)中只写出重做(redo)记录, 或者after-image. 在更新时, 事务上下文使用与撤销记录相同的本地机制来存储重做(redo)记录. 不同的是, 事务不需要保留所有重做记录, 因为它基本上在应用更改后不再读取它们. 因此, 与垃圾收集器类似, 日志管理器维护一个重做记录缓冲区的队列以进行刷新. 事务会填充其本地缓冲区, 并将其添加到队列中, 然后请求一个新的缓冲区用于后续更新. 在提交时, 事务管理器会将最后一个记录, 即提交记录, 插入缓冲区, 并手动将缓冲区添加到日志管理器的队列中.

然后, 日志管理器可以按照自己的节奏处理队列. 唯一的注意事项是, 因为数据库不允许报告事务已提交(报告是指向客户端写回响应. 我们可以在系统内部自由假设事务已提交), 日志管理器会为每个提交的事务接收一个回调函数, 承诺在提交记录持久化到磁盘时调用该回调函数. 在这种设置中, 来自单个事务和不同事务的依赖提交记录保证按顺序出现在记录缓冲区中, 因此我们不需要对记录进行编号. 日志管理器基本上会定期唤醒, 遍历队列并将记录从其内存格式序列化为磁盘格式(目前相同, 但很可能会在将来改变), 并在刷新提交记录时调用已注册的回调函数. 回调函数作为嵌入在提交记录中的C函数指针, 出于性能原因.
